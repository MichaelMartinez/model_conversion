# model_conversion

This is a conglomeration of projects to convert and quantize llm's

---

## Prjects used for conversion and quantization

* [GOTQ-for-LLaMa](https://github.com/qwopqwop200/GPTQ-for-LLaMa)
* [AutoGPTQ](https://github.com/PanQiWei/AutoGPTQ)
* [Text-generation-webui](https://github.com/oobabooga/text-generation-webui)
* [llama.cpp](https://github.com/ggerganov/llama.cpp)
* [RunPod - Containers](https://github.com/runpod/containers)
* [unfiltered-Wizard Dataset](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered)
* [h20-studiollm](https://github.com/h2oai/h2o-llmstudio)
* [WizardLM](https://github.com/nlpxucan/WizardLM)

### TheBloke

* This fella has done some amazing work:
* [DockerHub](https://hub.docker.com/u/thebloke)
  * `docker pull thebloke/runpod-pytorch-new`
* [HuggingFace](https://huggingface.co/TheBloke)
* Most of this repo is based off of discussions on the Discords with him...
